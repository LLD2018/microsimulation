% Rekapitulering av vad vi gjorde

\section{Overview of the changes to the code}

The computation can be modelled using the MapReduce programming model. After
analysing the code base, the conclusion was to first try to
parallelise using openmp, then extend to MPI.

First, to the map step of the code, we added
%\lstset{language=C}
\begin{lstlisting}
#pragma omp parallel shared(nthreads,chunk) private(i,tid,sim,diffTime,cumTime)
...
#pragma omp for schedule(static,1).
\end{lstlisting}
However, the reduce step was not straight forward to parallelise. In
the serial version of the code, the result was accumulated in an
associative array (\texttt{map} in C++ terminology ) with scope
throughout the whole module file (\emph{source file}) , and every
simulation result was incrementally added to the end result
associative array. In this reduction step several function calls was
made updating the result object, where the functions accessed it in
the scope of the file and not by a passed reference. So in the first
naive version, we just added \lstset{language=C++}
\begin{lstlisting}
#pragma omp critical
  {
  // updating the result, i.e., ``reduction step''
    report.add(FullState(state, ext_grade,
               dx, psa>=3.0, cohort), msg->kind,
               previousEventTime, now());
  }
\end{lstlisting}
around the section accessing the resource.

After some performance analysis, we realised that the reduction step
as implemented became the bottle-neck of the whole program. Instead,
we let each thread/process build up its contribution to the resulting
associative array in a private variable, and then merge these partial
results into the shared result object.

The R software also have a feature of using multi-cores, and we used
that one as a benchmark to the minimum performance we should obtain.

Summarising the steps, we label them
\begin{enumerate}
\item naive OpenMP (parallelising the map step)
\item improved OpenMP (first a thread-wise partial reduction, then
  reducing these partial results)
\item R automatic multi-threading.
\end{enumerate}

% R parallelisation

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "report"
%%% End:
